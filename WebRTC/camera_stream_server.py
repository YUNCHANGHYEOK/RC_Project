import asyncio  # ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” íŒŒì´ì¬ ë¹„ë™ê¸° ì…ì¶œë ¥ ëª¨ë“ˆ
import json  # ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ì„ ë•Œ ë¬¸ìì—´(JSON í¬ë§·)ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë“ˆ
import cv2  # OpenCV - ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì»´í“¨í„° ë¹„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬
import serial  # ì•„ë‘ì´ë…¸ì™€ì˜ ì‹œë¦¬ì–¼(USB) í†µì‹ ì„ ìœ„í•œ ëª¨ë“ˆ
import numpy as np  # í–‰ë ¬, ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ê³¼í•™ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬
import time  # í˜„ì¬ ì‹œê°„ í™•ì¸ ë˜ëŠ” ì§€ì—°(sleep) ì²˜ë¦¬ìš© ëª¨ë“ˆ
from av import VideoFrame  # aiortcì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¹„ë””ì˜¤ í”„ë ˆì„ í˜•ì‹
from aiortc import RTCPeerConnection, RTCSessionDescription, VideoStreamTrack  # WebRTC ì—°ê²°ì„ ìœ„í•œ í´ë˜ìŠ¤ë“¤
import websockets  # ì›¹ì†Œì¼“ ì„œë²„ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ëª¨ë“ˆ
from picamera2 import Picamera2  # ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì¹´ë©”ë¼ë¥¼ ì œì–´í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ì•„ë‘ì´ë…¸ì™€ ì‹œë¦¬ì–¼ í†µì‹ ì„ ì„¤ì •í•©ë‹ˆë‹¤. í¬íŠ¸ ì´ë¦„ì€ ì‹¤ì œ ì—°ê²°ëœ ì¥ì¹˜ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
arduino = serial.Serial('/dev/ttyUSB0', 9600)  # /dev/ttyUSB0 í¬íŠ¸ì— 9600bps ì†ë„ë¡œ ì—°ê²°
arduino.timeout = 0.1  # ë°ì´í„°ë¥¼ ì½ì„ ë•Œ ìµœëŒ€ 0.1ì´ˆ ëŒ€ê¸° í›„ ì¤‘ë‹¨í•˜ë„ë¡ ì„¤ì •

# WebRTCë¥¼ í†µí•´ ì˜ìƒ ë°ì´í„°ë¥¼ ì „ë‹¬í•  í´ë˜ìŠ¤ ì •ì˜
class CameraStream(VideoStreamTrack):  # aiortcì˜ VideoStreamTrack ìƒì†
    def __init__(self, ws=None):
        super().__init__()  # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        self.picam2 = Picamera2()  # ì¹´ë©”ë¼ ê°ì²´ ìƒì„±
        self.picam2.preview_configuration.main.size = (640, 480)  # ì˜ìƒ í•´ìƒë„ ì„¤ì •
        self.picam2.preview_configuration.main.format = "RGB888"  # ì˜ìƒ í¬ë§· ì„¤ì • (ì»¬ëŸ¬)
        self.picam2.configure("preview")  # í”„ë¦¬ë·° ì„¤ì • ì ìš©
        self.picam2.start()  # ì¹´ë©”ë¼ ì‹œì‘
        self.ws = ws  # WebSocket ê°ì²´ (ì˜ìƒ ì™¸ì— ì¢Œí‘œë„ ë³´ë‚´ê¸° ìœ„í•´ ì‚¬ìš©)
        self.prev_center = None  # ì´ì „ í”„ë ˆì„ì—ì„œ ì°¾ì€ ì¤‘ì‹¬ì  ì €ì¥
        self.last_valid_center = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ íš¨í–ˆë˜ ì¤‘ì‹¬ì  ì €ì¥
        self.lost_counter = 0  # ì¤‘ì‹¬ì ì„ ì°¾ì§€ ëª»í•œ íšŸìˆ˜ ëˆ„ì 
        self.max_lost_frames = 10  # ìµœëŒ€ 10ë²ˆê¹Œì§€ëŠ” ì´ì „ ì¤‘ì‹¬ì ì„ ìœ ì§€
        self.last_send_time = time.time()  # ë§ˆì§€ë§‰ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•œ ì‹œê°„ ê¸°ë¡

    async def recv(self):  # WebRTCì—ì„œ ì˜ìƒ í”„ë ˆì„ì„ ìš”ì²­í•  ë•Œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜
        try:
            # ì¹´ë©”ë¼ì—ì„œ í˜„ì¬ í”„ë ˆì„(ì´ë¯¸ì§€)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            frame = self.picam2.capture_array()
            if frame is None or frame.shape[0] == 0:
                print("âŒ í”„ë ˆì„ ìˆ˜ì‹  ì‹¤íŒ¨", flush=True)  # í”„ë ˆì„ì´ ë¹„ì—ˆìœ¼ë©´ ì¬ì‹œë„
                await asyncio.sleep(0.01)
                return await self.recv()

            # BGR ì´ë¯¸ì§€ë¥¼ HSV ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜ (ìƒ‰ ê¸°ë°˜ ì²˜ë¦¬ì— ìš©ì´)
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

            # ì–´ë‘ìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë²”ìœ„ ì„¤ì •
            lower_black = np.array([0, 0, 0])  # ìµœì†Œ HSV ê°’
            upper_black = np.array([180, 90, 170])  # ìµœëŒ€ HSV ê°’
            mask = cv2.inRange(hsv, lower_black, upper_black)  # ë²”ìœ„ ì•ˆì— ìˆìœ¼ë©´ í°ìƒ‰(255), ì•„ë‹ˆë©´ ê²€ì •(0)

            # ì¡ìŒì„ ì œê±°í•˜ê¸° ìœ„í•œ í˜•íƒœí•™ì  ì—°ì‚° (êµ¬ë© ì±„ìš°ê¸°)
            kernel = np.ones((3, 3), np.uint8)  # 3x3 í¬ê¸°ì˜ ì»¤ë„ ìƒì„±
            closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # ë‹«í˜ ì—°ì‚° ì ìš©

            color_frame = frame.copy()  # ì˜ìƒ ì‹œê°í™”ë¥¼ ìœ„í•œ ë³µì‚¬ë³¸ ìƒì„±
            center_x = center_y = None  # ì¤‘ì‹¬ ì¢Œí‘œ ì´ˆê¸°í™”

            # ROI1: ì˜ìƒ í•˜ë‹¨ ë¶€ë¶„, ì°¨ëŸ‰ ì œì–´ìš©ìœ¼ë¡œ ì¤‘ì‹¬ì  íƒì§€
            roi1_start, roi1_end = 320, 400  # ROI1 ë²”ìœ„ ì§€ì • (ì„¸ë¡œ ë°©í–¥)
            roi1_img = closed[roi1_start:roi1_end, :]  # ROI1 ì´ë¯¸ì§€ë¥¼ ì˜ë¼ëƒ„
            cv2.rectangle(color_frame, (0, roi1_start), (color_frame.shape[1], roi1_end), (0, 255, 0), 1)  # ì‹œê°í™”

            ys1, xs1 = np.where(roi1_img == 255)  # í°ìƒ‰ í”½ì…€ ì¢Œí‘œë§Œ ì¶”ì¶œ
            if len(xs1) > 100:
                # í°ìƒ‰ ì ì´ ì¶©ë¶„í•˜ë©´ ì§ì„ ì„ ì¶”ì •í•˜ì—¬ ì¤‘ì‹¬ ê³„ì‚°
                points1 = np.array(list(zip(xs1, ys1)), dtype=np.int32)
                [vx, vy, x0, y0] = cv2.fitLine(points1, cv2.DIST_L2, 0, 0.01, 0.01)  # ì§ì„  í”¼íŒ…
                t = ((roi1_end - roi1_start) // 2 - y0) / vy  # ìˆ˜ì§ ì¤‘ê°„ ìœ„ì¹˜ ê³„ì‚°
                cx = int(x0 + vx * t)  # ì¤‘ì‹¬ xì¢Œí‘œ ê³„ì‚°
                cy = int(y0 + vy * t) + roi1_start  # ì¤‘ì‹¬ yì¢Œí‘œ ê³„ì‚° (ì „ì²´ ì´ë¯¸ì§€ ê¸°ì¤€)
                center_x, center_y = cx, cy  # ì¤‘ì‹¬ ì¢Œí‘œ ì €ì¥
                self.last_valid_center = (center_x, center_y)  # ìœ íš¨í•œ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ë¡
                self.lost_counter = 0  # íƒì§€ ì‹¤íŒ¨ ì¹´ìš´í„° ì´ˆê¸°í™”

                # ì¤‘ì‹¬ì  ì‹œê°í™” (ì› 2ê°œ)
                cv2.circle(color_frame, (center_x, center_y), 2, (255, 0, 255), 1)
                cv2.circle(color_frame, (center_x, center_y), 2, (0, 255, 255), -1)
                print(f"ğŸ“Œ ROI1 ì¤‘ì‹¬: ({center_x},{center_y})", flush=True)
            else:
                # ì¤‘ì‹¬ì  íƒì§€ ì‹¤íŒ¨ ì²˜ë¦¬
                self.lost_counter += 1
                if self.last_valid_center and self.lost_counter < self.max_lost_frames:
                    # ìµœê·¼ ì¤‘ì‹¬ì„ ê³„ì† ì‚¬ìš©
                    center_x, center_y = self.last_valid_center
                    print(f"ğŸ” ì´ì „ ROI1 ì¢Œí‘œ ìœ ì§€: ({center_x},{center_y})", flush=True)
                else:
                    # ì¤‘ì‹¬ì  ë¬´íš¨í™”
                    center_x = center_y = None
                    self.last_valid_center = None
                    print("âŒ ROI1 ë¼ì¸ ê°ì§€ ì‹¤íŒ¨", flush=True)

            # ROI2: ì¤‘ê°„ ìƒë‹¨ ì˜ì—­ - ì˜ˆì¸¡ ë¶„ì„ìš© (ì¡°í–¥ ì˜ˆì¸¡ ë“±)
            roi2_start, roi2_end = 180, 260
            roi2_img = closed[roi2_start:roi2_end, :]
            cv2.rectangle(color_frame, (0, roi2_start), (color_frame.shape[1], roi2_end), (0, 255, 0), 1)

            ys2, xs2 = np.where(roi2_img == 255)
            if len(xs2) > 100:
                points2 = np.array(list(zip(xs2, ys2)), dtype=np.int32)
                [vx2, vy2, x02, y02] = cv2.fitLine(points2, cv2.DIST_L2, 0, 0.01, 0.01)
                t2 = ((roi2_end - roi2_start) // 2 - y02) / vy2
                cx2 = int(x02 + vx2 * t2)
                cy2 = int(y02 + vy2 * t2) + roi2_start
                cv2.circle(color_frame, (cx2, cy2), 2, (0, 0, 255), -1)  # ë¹¨ê°„ ì ìœ¼ë¡œ í‘œì‹œ
                print(f"ğŸ”® ROI2 ì˜ˆì¸¡ ì¤‘ì‹¬: ({cx2},{cy2})", flush=True)

            # ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ì•„ë‘ì´ë…¸ ë˜ëŠ” WebSocketìœ¼ë¡œ ì „ì†¡
            now = time.time()
            if center_x is not None and (center_x, center_y) != self.prev_center and (now - self.last_send_time) > 0.1:
                self.prev_center = (center_x, center_y)  # ë§ˆì§€ë§‰ ì „ì†¡ ì¢Œí‘œ ê¸°ë¡
                self.last_send_time = now  # ë§ˆì§€ë§‰ ì „ì†¡ ì‹œê°„ ê¸°ë¡
                try:
                    # ì•„ë‘ì´ë…¸ë¡œ x,y ì¢Œí‘œ ì „ì†¡
                    arduino.write(f"{center_x},{center_y}\n".encode())
                    print(f"ğŸ“¤ ì•„ë‘ì´ë…¸ë¡œ ì „ì†¡: {center_x},{center_y}", flush=True)
                    response = arduino.readline().decode().strip()
                    if response:
                        print(f"â†©ï¸ ì•„ë‘ì´ë…¸ ì‘ë‹µ: {response}", flush=True)
                except serial.SerialException as e:
                    print(f"âŒ ì•„ë‘ì´ë…¸ ì „ì†¡ ì‹¤íŒ¨: {e}", flush=True)

                # WebSocket í´ë¼ì´ì–¸íŠ¸ì—ë„ ì „ì†¡
                if self.ws:
                    try:
                        await self.ws.send(json.dumps({"x": center_x, "y": center_y}))
                    except:
                        pass
            elif center_x is None:
                # íƒì§€ ì‹¤íŒ¨ ì‹œ -1 ì „ì†¡
                arduino.write(b"-1,-1\n")

            await asyncio.sleep(0.005)  # í”„ë ˆì„ ê°„ ë”œë ˆì´
            pts, time_base = await self.next_timestamp()  # í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°
            video_frame = VideoFrame.from_ndarray(color_frame, format="bgr24")  # ì˜ìƒ í”„ë ˆì„ ìƒì„±
            video_frame.pts = pts
            video_frame.time_base = time_base
            return video_frame

        except Exception as e:
            print(f"âŒ recv() ë‚´ë¶€ ì˜¤ë¥˜: {e}", flush=True)
            await asyncio.sleep(0.01)
            return await self.recv()  # ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„

    def stop(self):
        self.picam2.stop()  # ì¹´ë©”ë¼ ì¢…ë£Œ

# WebRTC + WebSocket ì—°ê²°ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
async def handler(websocket):
    print("ğŸ”Œ WebSocket client connected")
    pc = RTCPeerConnection()  # WebRTC í”¼ì–´ ì—°ê²° ê°ì²´ ìƒì„±
    stream = CameraStream(ws=websocket)  # ì˜ìƒ ìŠ¤íŠ¸ë¦¼ ìƒì„±
    pc.addTrack(stream)  # í”¼ì–´ ì—°ê²°ì— ìŠ¤íŠ¸ë¦¼ ì¶”ê°€

    try:
        async for message in websocket:  # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹  ë°˜ë³µ
            data = json.loads(message)
            if data.get("type") == "offer":  # SDP offer ìˆ˜ì‹  ì‹œ ì²˜ë¦¬
                offer = RTCSessionDescription(sdp=data["sdp"], type=data["type"])
                await pc.setRemoteDescription(offer)  # ìƒëŒ€ë°© ì„¤ëª… ì €ì¥
                answer = await pc.createAnswer()  # ì‘ë‹µ ìƒì„±
                await pc.setLocalDescription(answer)  # ì‘ë‹µ ì„¤ì •
                await websocket.send(json.dumps({  # ì‘ë‹µì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
                    "sdp": pc.localDescription.sdp,
                    "type": pc.localDescription.type
                }))
                print("âœ… WebRTC ì—°ê²° ì™„ë£Œ")
    except Exception as e:
        print("âŒ WebSocket ì˜¤ë¥˜:", e)
    finally:
        await pc.close()  # WebRTC ì¢…ë£Œ
        stream.stop()  # ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
        print("ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ")

# WebSocket ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
async def main():
    print("ğŸŒ WebSocket ì„œë²„ ì‹œì‘: ws://0.0.0.0:8765")
    async with websockets.serve(handler, "0.0.0.0", 8765):  # 8765ë²ˆ í¬íŠ¸ì—ì„œ ì„œë²„ ì‹¤í–‰
        await asyncio.Future()  # ì„œë²„ê°€ ì¢…ë£Œë˜ì§€ ì•Šë„ë¡ ë¬´í•œ ëŒ€ê¸°

# í”„ë¡œê·¸ë¨ ì‹œì‘ ì§€ì 
if __name__ == "__main__":
    asyncio.run(main())  # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ (ë¹„ë™ê¸° ë°©ì‹)
